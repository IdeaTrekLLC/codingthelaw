{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Three Notebook Example\n",
    "\n",
    "For your final notebook, feel free to duplicate this notebook and edit as needed. \n",
    "\n",
    "\n",
    "## Load Some Stuff\n",
    "\n",
    "This is where we load libraires and the like so we can do what we need. If you get an error saying a module is not loaded, open a new terminal/cmd line and try running: `pip install [module name]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    inputFunc = raw_input\n",
    "except NameError:\n",
    "    inputFunc = input\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "import numpy as np\n",
    " \n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from patsy import dmatrices\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Custom functions\n",
    "\n",
    "def evaluate(pred, labels_test):\n",
    "    acc = accuracy_score(pred, labels_test)\n",
    "    print (\"Accuracey: %s\"%acc)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test, pred).ravel()\n",
    "\n",
    "    recall = tp / (tp + fp)\n",
    "    percision = tp / (tp + fn)\n",
    "    f1 = (2 / ((1/recall)+(1/percision)))\n",
    "\n",
    "    print (\"\")\n",
    "    print (\"True Negatives: %s\"%tn)\n",
    "    print (\"False Positives: %s\"%fp)\n",
    "    print (\"False Negatives: %s\"%fn)\n",
    "    print (\"True Positives: %s\"%tp)\n",
    "    print (\"Recall: %s\"%recall)\n",
    "    print (\"Precision: %s\"%percision)\n",
    "    print (\"F1 Score: %s\"%f1)\n",
    "\n",
    "def plot_bound(Z_val,data,col1,col2,binary):\n",
    "    # Z-val equals \"Yes\" value. E.g., \"Y\" or \"1\". \n",
    "    # data equals df\n",
    "    # col1 and col2 defines which colums to use from data\n",
    "    # Plot binary decision boundary. \n",
    "    # For this, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    \n",
    "    x_min = float(data.iloc[:,[col1]].min())-float(data.iloc[:,[col1]].min())*0.10 \n",
    "    x_max = float(data.iloc[:,[col1]].max()+float(data.iloc[:,[col1]].min())*0.10)\n",
    "    y_min = 0.0; \n",
    "    y_max = float(training.iloc[:,[col2]].max())+float(training.iloc[:,[col2]].max())*0.10\n",
    "    h_x = (x_max-x_min)/100  # step size in the mesh\n",
    "    h_y = (y_max-y_min)/100  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h_x), np.arange(y_min, y_max, h_y))\n",
    "    if binary == 1:\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])   \n",
    "        Z = np.where(Z==\"Y\",1,0)\n",
    "    else:\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.pcolormesh(xx, yy, Z)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Here we load the data we collected and get it all ready to feed to our statistical model(s). That is, we are trying to make a table with one **target** column and one or more **features**. Here I'm loading happiness.csv from: https://data.somervillema.gov/Happiness/Somerville-Happiness-Survey-responses-2011-2013-20/w898-3dfm Note: you can find information on the data elements at this link. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-cf91832f5f8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load and peek at your data. Change the file name as needed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mraw_data_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'scholarship.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mraw_data_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Michael McKeown\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Michael McKeown\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Michael McKeown\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    980\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Michael McKeown\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1763\u001b[0m                 values = self._maybe_parse_dates(values, i,\n\u001b[1;32m-> 1764\u001b[1;33m                                                  try_parse_dates=True)\n\u001b[0m\u001b[0;32m   1765\u001b[0m                 \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Michael McKeown\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_maybe_parse_dates\u001b[1;34m(self, values, index, try_parse_dates)\u001b[0m\n\u001b[0;32m   1821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_parse_dates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtry_parse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mtry_parse_dates\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_parse_dates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_date_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Michael McKeown\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_should_parse_dates\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m   1212\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1213\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1214\u001b[1;33m             \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Load and peek at your data. Change the file name as needed. \n",
    "raw_data_df = pd.read_csv('scholarship.csv', parse_dates=[0]) \n",
    "raw_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Academic Year</th>\n",
       "      <th>College Name</th>\n",
       "      <th>Sector Group</th>\n",
       "      <th>Headcount</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>SUNY BUFFALO</td>\n",
       "      <td>3-SUNY SO</td>\n",
       "      <td>1254</td>\n",
       "      <td>$2,135,027.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>SUNY BINGHAMTON</td>\n",
       "      <td>3-SUNY SO</td>\n",
       "      <td>1226</td>\n",
       "      <td>$3,026,812.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>SUNY STONY BROOK</td>\n",
       "      <td>3-SUNY SO</td>\n",
       "      <td>1038</td>\n",
       "      <td>$1,808,679.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>ROCHESTER INSTITUTE OF TECHLGY</td>\n",
       "      <td>5-INDEPENDENT</td>\n",
       "      <td>647</td>\n",
       "      <td>$525,392.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>CUNY HUNTER COLLEGE</td>\n",
       "      <td>1-CUNY SR</td>\n",
       "      <td>616</td>\n",
       "      <td>$507,087.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Academic Year                    College Name   Sector Group  Headcount  \\\n",
       "0    2015-01-01                    SUNY BUFFALO      3-SUNY SO       1254   \n",
       "1    2015-01-01                 SUNY BINGHAMTON      3-SUNY SO       1226   \n",
       "2    2015-01-01                SUNY STONY BROOK      3-SUNY SO       1038   \n",
       "3    2015-01-01  ROCHESTER INSTITUTE OF TECHLGY  5-INDEPENDENT        647   \n",
       "4    2015-01-01             CUNY HUNTER COLLEGE      1-CUNY SR        616   \n",
       "\n",
       "           Amount  \n",
       "0  $2,135,027.72   \n",
       "1  $3,026,812.78   \n",
       "2  $1,808,679.60   \n",
       "3    $525,392.13   \n",
       "4    $507,087.43   "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can explore rows with a specific value like so\n",
    "raw_data_df[raw_data_df[\"Academic Year\"]=='2015'].head() # remove .head() to see all entires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entire table: 2212 \n",
      "Size of entires matching filter: 290 \n"
     ]
    }
   ],
   "source": [
    "# You can count the number of rows like so\n",
    "print(\"Size of entire table: %s \"%len(raw_data_df))\n",
    "print(\"Size of entires matching filter: %s \"%len(raw_data_df[raw_data_df[\"Academic Year\"]=='2015']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can remove unwanted colums like so\n",
    "# for a single column\n",
    "processed_data_df = processed_data_df.drop('In.general..how.similar.are.you.to.other.people.you.know._2011', 1)\n",
    "# for multiple columns\n",
    "processed_data_df = processed_data_df.drop([\n",
    "                                            'How.satisfied.are.you.with.Somerville.as.a.place.to.live.',\n",
    "                                            'How.satisfied.are.you.with.your.neighborhood.'\n",
    "                                           ], 1)\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternativly, if you want to make a new table from a subset of columns, you can do so like this.\n",
    "processed_data_df = processed_data_df[[\n",
    "                                        'How.happy.do.you.feel.right.now.', \n",
    "                                        'How.satisfied.are.you.with.your.life.in.general.', \n",
    "                                        'What.is.your.annual.household.income.',\n",
    "                                        'Age.'\n",
    "                                     ]].copy()\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can rename columns like so.\n",
    "processed_data_df = processed_data_df.rename(columns={\n",
    "                                                        'How.happy.do.you.feel.right.now.': 'happy', \n",
    "                                                        'How.satisfied.are.you.with.your.life.in.general.': 'satisfied',\n",
    "                                                        'What.is.your.annual.household.income.': 'income',\n",
    "                                                        'Age.': 'age',\n",
    "                                                     })\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can replace values in a column based on logic like so\n",
    "# Note: I used the unique values found above to inform my logic.\n",
    "# That is, I took the unique text lables and translated them into numbers.\n",
    "# It's clear that different surveys had different buckets. So I probably \n",
    "# sould limit myself to years using the same metrics, but for our purposes\n",
    "# I'm just going to run with a quick and dirty translation. \n",
    "\n",
    "processed_data_df.loc[processed_data_df['income'] == 'Less than $10,000', 'income'] = 5000 \n",
    "processed_data_df.loc[processed_data_df['income'] == '10,000 - $19,999', 'income'] = 15000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$10,000 to $24,999', 'income'] = 17500\n",
    "processed_data_df.loc[processed_data_df['income'] == '20,000 - $29,999', 'income'] = 25000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$25,000 to $49,999', 'income'] = 37500\n",
    "processed_data_df.loc[processed_data_df['income'] == '30,000 - $39,999', 'income'] = 35000\n",
    "processed_data_df.loc[processed_data_df['income'] == '40,000 - $49,999', 'income'] = 45000\n",
    "processed_data_df.loc[processed_data_df['income'] == '50,000 - $59,999', 'income'] = 55000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$50,000 to $74,999', 'income'] = 62500\n",
    "processed_data_df.loc[processed_data_df['income'] == '60,000 - $69,999', 'income'] = 65000\n",
    "processed_data_df.loc[processed_data_df['income'] == '70,000 - $79,999', 'income'] = 75000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$75,000 to $99,999', 'income'] = 87500\n",
    "processed_data_df.loc[processed_data_df['income'] == '80,000 - $89,999', 'income'] = 85000\n",
    "processed_data_df.loc[processed_data_df['income'] == '90,000 - $99,999', 'income'] = 95000\n",
    "processed_data_df.loc[processed_data_df['income'] == '100,000 and up', 'income'] = 100000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$100,000 to $149,999', 'income'] = 125000 \n",
    "processed_data_df.loc[processed_data_df['income'] == '$150,000 or more', 'income'] = 150000\n",
    "\n",
    "processed_data_df.loc[processed_data_df['age'] == '18-21', 'age'] = 24\n",
    "processed_data_df.loc[processed_data_df['age'] == '18-24', 'age'] = 21\n",
    "processed_data_df.loc[processed_data_df['age'] == '22-25', 'age'] = 23.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '25-34', 'age'] = 29.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '26-30', 'age'] = 28\n",
    "processed_data_df.loc[processed_data_df['age'] == '31-40', 'age'] = 35.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '35-44', 'age'] = 39.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '41-50', 'age'] = 46.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '45-54', 'age'] = 48\n",
    "processed_data_df.loc[processed_data_df['age'] == '51-60', 'age'] = 55.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '55-64', 'age'] = 58\n",
    "processed_data_df.loc[processed_data_df['age'] == '61+', 'age'] = 61\n",
    "processed_data_df.loc[processed_data_df['age'] == '65-74', 'age'] = 69.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '75 or older', 'age'] = 75\n",
    "processed_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To make sure all of your columns are stored as numbers, use the pd.to_numeric method like so.\n",
    "processed_data_df = processed_data_df.apply(pd.to_numeric, errors='coerce')\n",
    "# errors='coerce' will set things that can't be converted to numbers to NaN\n",
    "# so you'll want to drop these like so.\n",
    "processed_data_df = processed_data_df.dropna()\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can add a columns like so.\n",
    "processed_data_df[\"happy_Y_N\"] = \"N\"\n",
    "processed_data_df[\"satisfied_Y_N\"] = \"N\"\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And then you can customize these new coulmns using the same method as above. \n",
    "processed_data_df.loc[processed_data_df['happy'] >= 5, 'happy_Y_N'] = \"Y\"\n",
    "processed_data_df.loc[processed_data_df['satisfied'] >= 5, 'satisfied_Y_N'] = \"Y\"\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm now going to make a set of tables to be used in training some models\n",
    "# The first set will be for linear regressions where the traget is numeric.\n",
    "# Happiness\n",
    "happy_lin_df = processed_data_df[[\n",
    "                               'happy', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "happy_lin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Satisfaction\n",
    "sat_lin_df = processed_data_df[[\n",
    "                               'satisfied', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "sat_lin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The second set will be for classifiers where the target is a class.\n",
    "# Happiness\n",
    "happy_class_df = processed_data_df[[\n",
    "                               'happy_Y_N', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "happy_class_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Satisfaction\n",
    "sat_class_df = processed_data_df[[\n",
    "                               'satisfied_Y_N', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "sat_class_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taining and Validation\n",
    "\n",
    "Above I created four datasets worth exploring: \n",
    "- **`happy_lin_df`**. The data needed to access *happiness* along a continuous variable.\n",
    "- **`sat_lin_df`**. The data needed to access *satisfaction* along a continuous variable.\n",
    "- **`happy_class_df`**. The data needed to access *happiness* as a categorical variable.\n",
    "- **`sat_class_df`**. The data needed to access *satisfaction* as a categorical variable.\n",
    "\n",
    "Let's take them each in turn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy_lin_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = happy_lin_df\n",
    "\n",
    "data = data[data[\"happy\"]<=10]\n",
    "\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"happy\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"income\", y=\"happy\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ols(\"happy ~ age + income\", training).fit()\n",
    "#model = ols(\"happy ~ age + income + np.power(age, 2) + np.power(income, 2)\", training).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rerun with SciKitLearn because it's easy to check accuracy\n",
    "features_train = training.drop(\"happy\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"happy\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"happy\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"happy\"].as_matrix(columns=None)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "clf = lm.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = metrics.r2_score(labels_test, pred)\n",
    "print(\"R squared:\",lm.score(features_train,labels_train))\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sat_lin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sat_lin_df\n",
    "\n",
    "data = data[data[\"satisfied\"]<=10]\n",
    "\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"satisfied\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"income\", y=\"satisfied\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ols(\"satisfied ~ age + income\", training).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rerun with SciKitLearn because it's easy to check accuracy\n",
    "\n",
    "features_train = training.drop(\"satisfied\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"satisfied\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"satisfied\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"satisfied\"].as_matrix(columns=None)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "clf = lm.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = metrics.r2_score(labels_test, pred)\n",
    "print(\"R squared:\",lm.score(features_train,labels_train))\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = happy_class_df\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]\n",
    "\n",
    "# Define the target (y) and feature(s) (X)\n",
    "features_train = training.drop(\"happy_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"happy_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"happy_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"happy_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "# What percentage of the time is target Y?\n",
    "print(\"Percentage of Ys: %s\\n\"%(len(data[data[\"happy_Y_N\"]==\"Y\"])/len(data)))\n",
    "\n",
    "#### initial visualization\n",
    "feature_1_no = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_2_no = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_1_yes = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "feature_2_yes = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "plt.scatter(feature_1_yes, feature_2_yes, color = \"g\", label=\"Happy\")\n",
    "plt.scatter(feature_1_no, feature_2_no, color = \"r\", label=\"Unhappy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"income\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept = False, C = 1e9)\n",
    "clf = model.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Logistic Regression\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "# Test some spot\n",
    "x_test = 70\n",
    "y_test = 160000\n",
    "print(\"\")\n",
    "print(clf.predict([[x_test,y_test]])[0])\n",
    "print(clf.predict_proba([[x_test,y_test]])[0][1])\n",
    "print(\"\")\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"\\nDecision Tree\")\n",
    "evaluate(pred, labels_test)\n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Random Forest\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"rbf\",probability=True)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"SVM\")\n",
    "evaluate(pred, labels_test)  \n",
    "#plot_bound(\"Y\",holdout,1,2,0) # plot doesn't work with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sat_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sat_class_df\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]\n",
    "\n",
    "# Define the target (y) and feature(s) (X)\n",
    "features_train = training.drop(\"satisfied_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"satisfied_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"satisfied_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"satisfied_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "# What percentage of the time is target Y?\n",
    "print(\"Percentage of Ys: %s\\n\"%(len(data[data[\"satisfied_Y_N\"]==\"Y\"])/len(data)))\n",
    "\n",
    "#### initial visualization\n",
    "feature_1_no = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_2_no = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_1_yes = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "feature_2_yes = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "plt.scatter(feature_1_yes, feature_2_yes, color = \"g\", label=\"Happy\")\n",
    "plt.scatter(feature_1_no, feature_2_no, color = \"r\", label=\"Unhappy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"income\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept = False, C = 1e9)\n",
    "clf = model.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Logistic Regression\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "# Test some spot\n",
    "x_test = 70\n",
    "y_test = 160000\n",
    "print(\"\")\n",
    "print(clf.predict([[x_test,y_test]])[0])\n",
    "print(clf.predict_proba([[x_test,y_test]])[0][1])\n",
    "print(\"\")\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"\\nDecision Tree\")\n",
    "evaluate(pred, labels_test)\n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Random Forest\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"rbf\",probability=True)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"SVM\")\n",
    "evaluate(pred, labels_test)  \n",
    "#plot_bound(\"Y\",holdout,1,2,0) # plot doesn't work with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
