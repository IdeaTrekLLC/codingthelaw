{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Three Notebook Example\n",
    "\n",
    "For your final notebook, feel free to duplicate this notebook and edit as needed. \n",
    "\n",
    "\n",
    "## Load Some Stuff\n",
    "\n",
    "This is where we load libraires and the like so we can do what we need. If you get an error saying a module is not loaded, open a new terminal/cmd line and try running: `pip install [module name]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    inputFunc = raw_input\n",
    "except NameError:\n",
    "    inputFunc = input\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "import numpy as np\n",
    " \n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from patsy import dmatrices\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Custom functions\n",
    "\n",
    "def evaluate(pred, labels_test):\n",
    "    acc = accuracy_score(pred, labels_test)\n",
    "    print (\"Accuracey: %s\"%acc)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test, pred).ravel()\n",
    "\n",
    "    recall = tp / (tp + fp)\n",
    "    percision = tp / (tp + fn)\n",
    "    f1 = (2 / ((1/recall)+(1/percision)))\n",
    "\n",
    "    print (\"\")\n",
    "    print (\"True Negatives: %s\"%tn)\n",
    "    print (\"False Positives: %s\"%fp)\n",
    "    print (\"False Negatives: %s\"%fn)\n",
    "    print (\"True Positives: %s\"%tp)\n",
    "    print (\"Recall: %s\"%recall)\n",
    "    print (\"Precision: %s\"%percision)\n",
    "    print (\"F1 Score: %s\"%f1)\n",
    "\n",
    "def plot_bound(Z_val,data,col1,col2,binary):\n",
    "    # Z-val equals \"Yes\" value. E.g., \"Y\" or \"1\". \n",
    "    # data equals df\n",
    "    # col1 and col2 defines which colums to use from data\n",
    "    # Plot binary decision boundary. \n",
    "    # For this, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    \n",
    "    x_min = float(data.iloc[:,[col1]].min())-float(data.iloc[:,[col1]].min())*0.10 \n",
    "    x_max = float(data.iloc[:,[col1]].max()+float(data.iloc[:,[col1]].min())*0.10)\n",
    "    y_min = 0.0; \n",
    "    y_max = float(training.iloc[:,[col2]].max())+float(training.iloc[:,[col2]].max())*0.10\n",
    "    h_x = (x_max-x_min)/100  # step size in the mesh\n",
    "    h_y = (y_max-y_min)/100  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h_x), np.arange(y_min, y_max, h_y))\n",
    "    if binary == 1:\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])   \n",
    "        Z = np.where(Z==\"Y\",1,0)\n",
    "    else:\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.pcolormesh(xx, yy, Z)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Here we load the data we collected and get it all ready to feed to our statistical model(s). That is, we are trying to make a table with one **target** column and one or more **features**. Here I'm loading happiness.csv from: https://data.somervillema.gov/Happiness/Somerville-Happiness-Survey-responses-2011-2013-20/w898-3dfm Note: you can find information on the data elements at this link. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Cocaine</th>\n",
       "      <th>Fentan1l</th>\n",
       "      <th>Ox1codone</th>\n",
       "      <th>Ox1morphone</th>\n",
       "      <th>EtOH</th>\n",
       "      <th>H1drocodone</th>\n",
       "      <th>Benzodiazepine</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Amphet</th>\n",
       "      <th>Tramad</th>\n",
       "      <th>Morphine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Age Heroin  Cocaine  Fentan1l  Ox1codone  Ox1morphone  EtOH  \\\n",
       "0    Male   41      0        0         1          0            0     0   \n",
       "1  Female   48      1        0         1          1            0     0   \n",
       "2    Male   28      1        0         1          0            0     0   \n",
       "3    Male   40      0        0         1          1            0     0   \n",
       "4    Male   52      1        1         0          0            0     1   \n",
       "\n",
       "   H1drocodone  Benzodiazepine  Methadone  Amphet  Tramad Morphine   \n",
       "0            0               0          0       0       0         0  \n",
       "1            0               1          0       0       0         0  \n",
       "2            0               0          0       0       0         0  \n",
       "3            0               1          0       0       0         0  \n",
       "4            0               0          0       0       0         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and peek at your data. Change the file name as needed. \n",
    "raw_data_df = pd.read_csv('overdose.csv', parse_dates=[0]) \n",
    "raw_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '1' ' ']\n",
      "[41 48 28 40 52 33 22 45 62 46 31 27 37 55 34 50 24 32 42 60 58 61 43 63 51\n",
      " 38 19 29 26 47 39 49 56 44 35 36 25 30 21 54 59 23 53 20 64 66 67 71 72 57\n",
      " 65 69 68 17 73]\n"
     ]
    }
   ],
   "source": [
    "# You can explore unique entires by stating the column and using .unique() like this:\n",
    "print(raw_data_df[\"Heroin\"].unique())\n",
    "print(raw_data_df[\"Age\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Cocaine</th>\n",
       "      <th>Fentan1l</th>\n",
       "      <th>Ox1codone</th>\n",
       "      <th>Ox1morphone</th>\n",
       "      <th>EtOH</th>\n",
       "      <th>H1drocodone</th>\n",
       "      <th>Benzodiazepine</th>\n",
       "      <th>Methadone</th>\n",
       "      <th>Amphet</th>\n",
       "      <th>Tramad</th>\n",
       "      <th>Morphine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sex  Age Heroin  Cocaine  Fentan1l  Ox1codone  Ox1morphone  EtOH  \\\n",
       "1   Female   48      1        0         1          1            0     0   \n",
       "2     Male   28      1        0         1          0            0     0   \n",
       "4     Male   52      1        1         0          0            0     1   \n",
       "6   Female   33      1        0         1          0            0     0   \n",
       "10  Female   46      1        1         1          0            0     0   \n",
       "\n",
       "    H1drocodone  Benzodiazepine  Methadone  Amphet  Tramad Morphine   \n",
       "1             0               1          0       0       0         0  \n",
       "2             0               0          0       0       0         0  \n",
       "4             0               0          0       0       0         0  \n",
       "6             0               0          0       0       0         0  \n",
       "10            0               0          0       0       0         0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can explore rows with a specific value like so\n",
    "raw_data_df[raw_data_df[\"Heroin\"]=='1'].head() # remove .head() to see all entires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entire table: 542 \n",
      "Size of entires matching filter: 0 \n"
     ]
    }
   ],
   "source": [
    "# You can count the number of rows like so\n",
    "print(\"Size of entire table: %s \"%len(raw_data_df))\n",
    "print(\"Size of entires matching filter: %s \"%len(raw_data_df[raw_data_df[\"Heroin\"]=='Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Herion'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/devonbodey/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2392\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2393\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Herion'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7a5d94717764>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You can invert a match by using the 'not equal' evaluation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of entires matching filter: %s \"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mraw_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Herion\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mraw_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mraw_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Heroin\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/devonbodey/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2060\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2062\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/devonbodey/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2067\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2069\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/devonbodey/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1534\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1535\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/devonbodey/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/devonbodey/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2393\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2395\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5239)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5085)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20405)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20359)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Herion'"
     ]
    }
   ],
   "source": [
    "# You can invert a match by using the 'not equal' evaluation.\n",
    "print(\"Size of entires matching filter: %s \"%len(raw_data_df[raw_data_df[\"Herion\"]!='0']))\n",
    "raw_data_df[raw_data_df[\"Heroin\"]!='0'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can make a new table from your filtered rows like so\n",
    "processed_data_df = raw_data_df[raw_data_df[\"What.is.your.annual.household.income.\"]!='R']\n",
    "processed_data_df = processed_data_df[processed_data_df[\"Age.\"]!='R']\n",
    "# Note how I filtered first on raw_data_df and then on processed_data_df\n",
    "\n",
    "# Now let's remove all students\n",
    "processed_data_df = processed_data_df[processed_data_df[\"Are.you.a.student.\"]!='Yes']\n",
    "\n",
    "# So how many entires are there?\n",
    "print(\"Size of entire table: %s \"%len(processed_data_df))\n",
    "# Let's peak at the table.\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for the special case of when a calue is NaN, you can filter based on the value not being null (i.e., empty)\n",
    "processed_data_df = processed_data_df[pd.notnull(processed_data_df[\"What.is.your.annual.household.income.\"])]\n",
    "processed_data_df = processed_data_df[pd.notnull(processed_data_df[\"Age.\"])]\n",
    "print(\"Size of entire table: %s \"%len(processed_data_df)) # in the example data, this gets rid of a few rows\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can remove unwanted colums like so\n",
    "# for a single column\n",
    "processed_data_df = processed_data_df.drop('In.general..how.similar.are.you.to.other.people.you.know._2011', 1)\n",
    "# for multiple columns\n",
    "processed_data_df = processed_data_df.drop([\n",
    "                                            'How.satisfied.are.you.with.Somerville.as.a.place.to.live.',\n",
    "                                            'How.satisfied.are.you.with.your.neighborhood.'\n",
    "                                           ], 1)\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternativly, if you want to make a new table from a subset of columns, you can do so like this.\n",
    "processed_data_df = processed_data_df[[\n",
    "                                        'How.happy.do.you.feel.right.now.', \n",
    "                                        'How.satisfied.are.you.with.your.life.in.general.', \n",
    "                                        'What.is.your.annual.household.income.',\n",
    "                                        'Age.'\n",
    "                                     ]].copy()\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can rename columns like so.\n",
    "processed_data_df = processed_data_df.rename(columns={\n",
    "                                                        'How.happy.do.you.feel.right.now.': 'happy', \n",
    "                                                        'How.satisfied.are.you.with.your.life.in.general.': 'satisfied',\n",
    "                                                        'What.is.your.annual.household.income.': 'income',\n",
    "                                                        'Age.': 'age',\n",
    "                                                     })\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-53432c8985c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# I'm just going to run with a quick and dirty translation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Heroin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Heroin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cocaine'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cocaine'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Fentanyl'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Fentanyl'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "# You can replace values in a column based on logic like so\n",
    "# Note: I used the unique values found above to inform my logic.\n",
    "# That is, I took the unique text lables and translated them into numbers.\n",
    "# It's clear that different surveys had different buckets. So I probably \n",
    "# sould limit myself to years using the same metrics, but for our purposes\n",
    "# I'm just going to run with a quick and dirty translation. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processed_data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f748d7ac3a9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To make sure all of your columns are stored as numbers, use the pd.to_numeric method like so.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprocessed_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# errors='coerce' will set things that can't be converted to numbers to NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# so you'll want to drop these like so.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprocessed_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processed_data_df' is not defined"
     ]
    }
   ],
   "source": [
    "# To make sure all of your columns are stored as numbers, use the pd.to_numeric method like so.\n",
    "processed_data_df = processed_data_df.apply(pd.to_numeric, errors='coerce')\n",
    "# errors='coerce' will set things that can't be converted to numbers to NaN\n",
    "# so you'll want to drop these like so.\n",
    "processed_data_df = processed_data_df.dropna()\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can add a columns like so.\n",
    "processed_data_df[\"happy_Y_N\"] = \"N\"\n",
    "processed_data_df[\"satisfied_Y_N\"] = \"N\"\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And then you can customize these new coulmns using the same method as above. \n",
    "processed_data_df.loc[processed_data_df['happy'] >= 5, 'happy_Y_N'] = \"Y\"\n",
    "processed_data_df.loc[processed_data_df['satisfied'] >= 5, 'satisfied_Y_N'] = \"Y\"\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm now going to make a set of tables to be used in training some models\n",
    "# The first set will be for linear regressions where the traget is numeric.\n",
    "# Happiness\n",
    "happy_lin_df = processed_data_df[[\n",
    "                               'happy', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "happy_lin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Satisfaction\n",
    "sat_lin_df = processed_data_df[[\n",
    "                               'satisfied', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "sat_lin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The second set will be for classifiers where the target is a class.\n",
    "# Happiness\n",
    "happy_class_df = processed_data_df[[\n",
    "                               'happy_Y_N', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "happy_class_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Satisfaction\n",
    "sat_class_df = processed_data_df[[\n",
    "                               'satisfied_Y_N', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "sat_class_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taining and Validation\n",
    "\n",
    "Above I created four datasets worth exploring: \n",
    "- **`happy_lin_df`**. The data needed to access *happiness* along a continuous variable.\n",
    "- **`sat_lin_df`**. The data needed to access *satisfaction* along a continuous variable.\n",
    "- **`happy_class_df`**. The data needed to access *happiness* as a categorical variable.\n",
    "- **`sat_class_df`**. The data needed to access *satisfaction* as a categorical variable.\n",
    "\n",
    "Let's take them each in turn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy_lin_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = happy_lin_df\n",
    "\n",
    "data = data[data[\"happy\"]<=10]\n",
    "\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"happy\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"income\", y=\"happy\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ols(\"happy ~ age + income\", training).fit()\n",
    "#model = ols(\"happy ~ age + income + np.power(age, 2) + np.power(income, 2)\", training).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rerun with SciKitLearn because it's easy to check accuracy\n",
    "features_train = training.drop(\"happy\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"happy\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"happy\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"happy\"].as_matrix(columns=None)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "clf = lm.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = metrics.r2_score(labels_test, pred)\n",
    "print(\"R squared:\",lm.score(features_train,labels_train))\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sat_lin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sat_lin_df\n",
    "\n",
    "data = data[data[\"satisfied\"]<=10]\n",
    "\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"satisfied\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"income\", y=\"satisfied\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ols(\"satisfied ~ age + income\", training).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rerun with SciKitLearn because it's easy to check accuracy\n",
    "\n",
    "features_train = training.drop(\"satisfied\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"satisfied\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"satisfied\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"satisfied\"].as_matrix(columns=None)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "clf = lm.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = metrics.r2_score(labels_test, pred)\n",
    "print(\"R squared:\",lm.score(features_train,labels_train))\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = happy_class_df\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]\n",
    "\n",
    "# Define the target (y) and feature(s) (X)\n",
    "features_train = training.drop(\"happy_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"happy_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"happy_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"happy_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "# What percentage of the time is target Y?\n",
    "print(\"Percentage of Ys: %s\\n\"%(len(data[data[\"happy_Y_N\"]==\"Y\"])/len(data)))\n",
    "\n",
    "#### initial visualization\n",
    "feature_1_no = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_2_no = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_1_yes = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "feature_2_yes = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "plt.scatter(feature_1_yes, feature_2_yes, color = \"g\", label=\"Happy\")\n",
    "plt.scatter(feature_1_no, feature_2_no, color = \"r\", label=\"Unhappy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"income\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept = False, C = 1e9)\n",
    "clf = model.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Logistic Regression\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "# Test some spot\n",
    "x_test = 70\n",
    "y_test = 160000\n",
    "print(\"\")\n",
    "print(clf.predict([[x_test,y_test]])[0])\n",
    "print(clf.predict_proba([[x_test,y_test]])[0][1])\n",
    "print(\"\")\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"\\nDecision Tree\")\n",
    "evaluate(pred, labels_test)\n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Random Forest\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"rbf\",probability=True)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"SVM\")\n",
    "evaluate(pred, labels_test)  \n",
    "#plot_bound(\"Y\",holdout,1,2,0) # plot doesn't work with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sat_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sat_class_df\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]\n",
    "\n",
    "# Define the target (y) and feature(s) (X)\n",
    "features_train = training.drop(\"satisfied_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"satisfied_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"satisfied_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"satisfied_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "# What percentage of the time is target Y?\n",
    "print(\"Percentage of Ys: %s\\n\"%(len(data[data[\"satisfied_Y_N\"]==\"Y\"])/len(data)))\n",
    "\n",
    "#### initial visualization\n",
    "feature_1_no = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_2_no = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_1_yes = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "feature_2_yes = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "plt.scatter(feature_1_yes, feature_2_yes, color = \"g\", label=\"Happy\")\n",
    "plt.scatter(feature_1_no, feature_2_no, color = \"r\", label=\"Unhappy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"income\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept = False, C = 1e9)\n",
    "clf = model.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Logistic Regression\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "# Test some spot\n",
    "x_test = 70\n",
    "y_test = 160000\n",
    "print(\"\")\n",
    "print(clf.predict([[x_test,y_test]])[0])\n",
    "print(clf.predict_proba([[x_test,y_test]])[0][1])\n",
    "print(\"\")\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"\\nDecision Tree\")\n",
    "evaluate(pred, labels_test)\n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Random Forest\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"rbf\",probability=True)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"SVM\")\n",
    "evaluate(pred, labels_test)  \n",
    "#plot_bound(\"Y\",holdout,1,2,0) # plot doesn't work with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
