{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Three Notebook Example\n",
    "\n",
    "For your final notebook, feel free to duplicate this notebook and edit as needed. \n",
    "\n",
    "\n",
    "## Load Some Stuff\n",
    "\n",
    "This is where we load libraires and the like so we can do what we need. If you get an error saying a module is not loaded, open a new terminal/cmd line and try running: `pip install [module name]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    inputFunc = raw_input\n",
    "except NameError:\n",
    "    inputFunc = input\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "import numpy as np\n",
    " \n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from patsy import dmatrices\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Custom functions\n",
    "\n",
    "def evaluate(pred, labels_test):\n",
    "    acc = accuracy_score(pred, labels_test)\n",
    "    print (\"Accuracey: %s\"%acc)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test, pred).ravel()\n",
    "\n",
    "    recall = tp / (tp + fp)\n",
    "    percision = tp / (tp + fn)\n",
    "    f1 = (2 / ((1/recall)+(1/percision)))\n",
    "\n",
    "    print (\"\")\n",
    "    print (\"True Negatives: %s\"%tn)\n",
    "    print (\"False Positives: %s\"%fp)\n",
    "    print (\"False Negatives: %s\"%fn)\n",
    "    print (\"True Positives: %s\"%tp)\n",
    "    print (\"Recall: %s\"%recall)\n",
    "    print (\"Precision: %s\"%percision)\n",
    "    print (\"F1 Score: %s\"%f1)\n",
    "\n",
    "def plot_bound(Z_val,data,col1,col2,binary):\n",
    "    # Z-val equals \"Yes\" value. E.g., \"Y\" or \"1\". \n",
    "    # data equals df\n",
    "    # col1 and col2 defines which colums to use from data\n",
    "    # Plot binary decision boundary. \n",
    "    # For this, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    \n",
    "    x_min = float(data.iloc[:,[col1]].min())-float(data.iloc[:,[col1]].min())*0.10 \n",
    "    x_max = float(data.iloc[:,[col1]].max()+float(data.iloc[:,[col1]].min())*0.10)\n",
    "    y_min = 0.0; \n",
    "    y_max = float(training.iloc[:,[col2]].max())+float(training.iloc[:,[col2]].max())*0.10\n",
    "    h_x = (x_max-x_min)/100  # step size in the mesh\n",
    "    h_y = (y_max-y_min)/100  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h_x), np.arange(y_min, y_max, h_y))\n",
    "    if binary == 1:\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])   \n",
    "        Z = np.where(Z==\"Y\",1,0)\n",
    "    else:\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.pcolormesh(xx, yy, Z)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Here we load the data we collected and get it all ready to feed to our statistical model(s). That is, we are trying to make a table with one **target** column and one or more **features**. Here I'm loading happiness.csv from: https://data.somervillema.gov/Happiness/Somerville-Happiness-Survey-responses-2011-2013-20/w898-3dfm Note: you can find information on the data elements at this link. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Total</th>\n",
       "      <th>BPD</th>\n",
       "      <th>BFD</th>\n",
       "      <th>EMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>2603</td>\n",
       "      <td>1969</td>\n",
       "      <td>259</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>2414</td>\n",
       "      <td>1852</td>\n",
       "      <td>206</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>2487</td>\n",
       "      <td>1872</td>\n",
       "      <td>235</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>2328</td>\n",
       "      <td>1695</td>\n",
       "      <td>241</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>2478</td>\n",
       "      <td>1915</td>\n",
       "      <td>225</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year  Month  Total   BPD  BFD  EMS\n",
       "0 2010-01-01     11   2603  1969  259  375\n",
       "1 2010-01-01     11   2414  1852  206  356\n",
       "2 2010-01-01     11   2487  1872  235  380\n",
       "3 2010-01-01     11   2328  1695  241  392\n",
       "4 2010-01-01     11   2478  1915  225  338"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and peek at your data. Change the file name as needed. \n",
    "raw_data_df = pd.read_csv('911.csv', parse_dates=[0]) \n",
    "raw_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 12  1  2  3  4  5  6  7  8  9 10]\n",
      "[2603 2414 2487 2328 2478 2297 2113 2542 2523 2496 2108 2665 2443 2136 2367\n",
      " 2500 2463 2533 2631 2324 2020 2431 2489 2217 1413 1935 2080 1862 2318 2400\n",
      " 2497 2483 2577 2176 1985 2198 2306 2394 2447 2248 1910 2311 2289 2334 2232\n",
      " 2504 2267 1959 2646 2355 2456 2302 1787 1086 1533 2228 2215 2237 2291 2517\n",
      " 1796 2258 2348 2195 2449 1878 1779 2229 2410 2975 2383 1895 1992 2526 2653\n",
      " 2614 2200 2308 2213 2561 2684 2432 2530 2787 2492 2226 2616 2507 2675 2833\n",
      " 2506 2230 2750 2593 2582 2584 2642 2359 2196 2574 2571 2832 2404 2011 2079\n",
      " 2336 2397 2335 2345 1886 2409 2625 2454 2471 2553 2520 2175 2479 2403 2617\n",
      " 2030 2442 2354 2635 2836 2325 2339 2575 2285 1993 2480 2588 2485 2509 2392\n",
      " 2234 2448 2619 2583 2590 2615 2559 2199 2649 2462 2294 2589 2651 2194 2387\n",
      " 2301 2424 1978 2634 2726 2989 2562 2630 2606 2691 2946 2560 2641 2624 3256\n",
      " 2993 2499 2116 2426 2436 2643 2799 2925 2511 2550 2850 2965 2908 3034 2441\n",
      " 2287 2764 2820 2740 2868 2676 2365 2704 2849 2738 2190 2690 2748 2707 2922\n",
      " 2259 2752 2508 2429 2564 2391 2679 2902 2834 2808 2903 2737 2647 2974 3040\n",
      " 2777 2867 2586 2776 2749 2481 2758 2807 3055 2733 2374 2549 2687 2725 2886\n",
      " 2678 2715 2428 2727 2667 2876 2613 2192 2747 2873 2760 2585 2233 2353 2677\n",
      " 2813 2372 2618 2884 3150 2800 2797 2789 2260 2524 2701 3036 3005 2757 2872\n",
      " 2981 2689 2411 2724 2573 2914 2961 2930 2791 2817 2907 2774 2344 2633 2772\n",
      " 2761 2393 2490 2622 2620 2711 2923 2720 2778 2795 2604 2721 2654 2731 2602\n",
      " 2973 2545 2710 2627 2714 2664 2839 2505 2304 2753 2503 2468 2611 2580 2534\n",
      " 2621 2552 2495 2567 2408 1435 2174 2087 2605 2934 2221 2713 2437 2110 2435\n",
      " 2112 2510 2594 2695 1867 1361 1865 2337 2250 2644 2077 2491 2656 3253 2716\n",
      " 2189 2438 2794 2673 2124 2744 2756 2692 2843 2205 2822 2486 2666 2763 2806\n",
      " 2682 2835 2482 2273 2648 2751 2838 2440 2254 2681 2636 2768 2818 2600 2349\n",
      " 2340 2767 2735 2668 2558 2639 2844 2655 2897 2548 2295 2953 3065 2863 3044\n",
      " 2968 2928 3137 3019 2719 2251 2821 2856 2723 2957 2551 2330 2792 3002 2997\n",
      " 2181 3209 3154 2977 3144 3347 3046 2936 3060 2978 2845 2892 2755 2531 2890\n",
      " 2851 3018 2909 2955 3050 3116 2706 3000 2828 3080 2963 2657 2986 2992 3041\n",
      " 3091 3156 3013 2685 2599 3162 3210 3330 3261 2730 3128 3101 3135 2899 2998\n",
      " 2881 3284 3054 3051 3314 3379 3164 3031 2904 3039 3073 3153 2980 3424 3640\n",
      " 3478 3131 3011 2984 2964 3072 3017 2885 2645 3001 2926 3170 3163 2814 2877\n",
      " 3130 3085 3121 2869 2841 3159 3272 3004 2952 2938 3098 2931 2878 3053 3030\n",
      " 3125 2935 3003 3029 2962 2861 3095 3103 3198 3404 3086 3028 3278 3306 3134\n",
      " 2798 3118 3276 3084 2693 3237 3160 3158 3112 2672 2906 3066 3373 3052 3110\n",
      " 3010 2805 2476 3070 3197 2816 3020 2966 3205 2932 2996 2785 2416 2592 2859\n",
      " 3081 2773 2538 2921 2889 2880 3045 2475 2940 1611 2381 2225 2883 2823 2722\n",
      " 2983 2862 2745 2910 2911 2990 3120 2729 2331 2809 3043 3021 2527 2243 2282\n",
      " 1488 2148 2688 2698 2771 2941 2540 2879 2905 2811 2855 2959 2699 2924 2455\n",
      " 2314 2927 2842 2728 2775 3083 2937 2888 2298 2419 2111 2661 2658 2418 2674\n",
      " 2671 2598 2452 2784 2430 3105 3047 2303 2901 2788 2541 2960 2898 2680 2765\n",
      " 2612 3087 2857 3035 3119 2999 3174 2477 3235 2912 3229 2694 3161 3024 3025\n",
      " 3194 3190 3069 2732 3187 3096 3061 2608 2581 3390 3470 3206 3193 3265 3317\n",
      " 3180 3015 3402 3064 2860 3252 3115 2915 3123 2810 3280 3346 3292 2976 3037\n",
      " 3077 3273 3556 3413 3189 2933 3211 3092 3351 3376 3490 2970 2950 3350 3007\n",
      " 3132 2782 3042 3245 3308 3114 3234 3056 3049 3122 3257 3106 3221 2944 3466\n",
      " 3143 3228 3022 3426 3167 3094 3136 3231 3139 2840 2979 2597 3117 3155 3307\n",
      " 2994 2743 2556 2951 2948 2988 2939 2824 2919 2461 2754 3271 2515 2967 2958\n",
      " 2384 2796 2660 2864 2985 2578 2317 2705 2870 1574 2819 3111 3151 2579 2358\n",
      " 2434 2319 1474 2313 2160 2837 2893 2388 2853 2918 2427 2801 2917 2987 2283\n",
      " 2848 2686 2493 2971 2623 2450 2830 2368 2827 2347 3012 2465 3063 3244 3099\n",
      " 2875]\n"
     ]
    }
   ],
   "source": [
    "# You can explore unique entires by stating the column and using .unique() like this:\n",
    "print(raw_data_df[\"Month\"].unique())\n",
    "print(raw_data_df[\"Total\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Total</th>\n",
       "      <th>BPD</th>\n",
       "      <th>BFD</th>\n",
       "      <th>EMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>3256</td>\n",
       "      <td>2672</td>\n",
       "      <td>218</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>3034</td>\n",
       "      <td>2286</td>\n",
       "      <td>298</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>7</td>\n",
       "      <td>3040</td>\n",
       "      <td>2325</td>\n",
       "      <td>292</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>7</td>\n",
       "      <td>3055</td>\n",
       "      <td>2190</td>\n",
       "      <td>354</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>3150</td>\n",
       "      <td>2148</td>\n",
       "      <td>671</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>9</td>\n",
       "      <td>3036</td>\n",
       "      <td>2361</td>\n",
       "      <td>271</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>9</td>\n",
       "      <td>3005</td>\n",
       "      <td>2281</td>\n",
       "      <td>280</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3253</td>\n",
       "      <td>2646</td>\n",
       "      <td>241</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3034</td>\n",
       "      <td>2417</td>\n",
       "      <td>219</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3065</td>\n",
       "      <td>2321</td>\n",
       "      <td>303</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3044</td>\n",
       "      <td>2337</td>\n",
       "      <td>263</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3137</td>\n",
       "      <td>2477</td>\n",
       "      <td>238</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3019</td>\n",
       "      <td>2392</td>\n",
       "      <td>226</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3019</td>\n",
       "      <td>2381</td>\n",
       "      <td>252</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3002</td>\n",
       "      <td>2385</td>\n",
       "      <td>215</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3209</td>\n",
       "      <td>2565</td>\n",
       "      <td>239</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3154</td>\n",
       "      <td>2589</td>\n",
       "      <td>224</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3144</td>\n",
       "      <td>2485</td>\n",
       "      <td>238</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3347</td>\n",
       "      <td>2356</td>\n",
       "      <td>316</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3046</td>\n",
       "      <td>2401</td>\n",
       "      <td>253</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3060</td>\n",
       "      <td>2407</td>\n",
       "      <td>272</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3040</td>\n",
       "      <td>2398</td>\n",
       "      <td>248</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>3018</td>\n",
       "      <td>2374</td>\n",
       "      <td>253</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>3050</td>\n",
       "      <td>2502</td>\n",
       "      <td>197</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>3116</td>\n",
       "      <td>2448</td>\n",
       "      <td>236</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>3050</td>\n",
       "      <td>2447</td>\n",
       "      <td>228</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>3080</td>\n",
       "      <td>2457</td>\n",
       "      <td>238</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>3137</td>\n",
       "      <td>2534</td>\n",
       "      <td>211</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>3041</td>\n",
       "      <td>2470</td>\n",
       "      <td>214</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>3091</td>\n",
       "      <td>2475</td>\n",
       "      <td>232</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>3083</td>\n",
       "      <td>2329</td>\n",
       "      <td>298</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>3307</td>\n",
       "      <td>2595</td>\n",
       "      <td>257</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>3044</td>\n",
       "      <td>2424</td>\n",
       "      <td>215</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>3101</td>\n",
       "      <td>2465</td>\n",
       "      <td>217</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10</td>\n",
       "      <td>3040</td>\n",
       "      <td>2420</td>\n",
       "      <td>222</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>3271</td>\n",
       "      <td>2530</td>\n",
       "      <td>281</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>11</td>\n",
       "      <td>3042</td>\n",
       "      <td>2335</td>\n",
       "      <td>250</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>3040</td>\n",
       "      <td>2350</td>\n",
       "      <td>250</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>3111</td>\n",
       "      <td>2427</td>\n",
       "      <td>261</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>3151</td>\n",
       "      <td>2449</td>\n",
       "      <td>246</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>3051</td>\n",
       "      <td>2435</td>\n",
       "      <td>221</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>3106</td>\n",
       "      <td>2373</td>\n",
       "      <td>299</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>3066</td>\n",
       "      <td>2412</td>\n",
       "      <td>233</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>3049</td>\n",
       "      <td>2382</td>\n",
       "      <td>241</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>3013</td>\n",
       "      <td>2315</td>\n",
       "      <td>264</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>3004</td>\n",
       "      <td>2302</td>\n",
       "      <td>233</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3012</td>\n",
       "      <td>2345</td>\n",
       "      <td>268</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3021</td>\n",
       "      <td>2402</td>\n",
       "      <td>216</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3053</td>\n",
       "      <td>2459</td>\n",
       "      <td>194</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>3001</td>\n",
       "      <td>2374</td>\n",
       "      <td>216</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3018</td>\n",
       "      <td>2420</td>\n",
       "      <td>189</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3086</td>\n",
       "      <td>2421</td>\n",
       "      <td>231</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3063</td>\n",
       "      <td>2351</td>\n",
       "      <td>262</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3007</td>\n",
       "      <td>2388</td>\n",
       "      <td>206</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3024</td>\n",
       "      <td>2363</td>\n",
       "      <td>230</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3150</td>\n",
       "      <td>2448</td>\n",
       "      <td>252</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3101</td>\n",
       "      <td>2424</td>\n",
       "      <td>243</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3244</td>\n",
       "      <td>2541</td>\n",
       "      <td>269</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3099</td>\n",
       "      <td>2456</td>\n",
       "      <td>233</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3051</td>\n",
       "      <td>2383</td>\n",
       "      <td>245</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Year  Month  Total   BPD  BFD  EMS\n",
       "192  2011-01-01      5   3256  2672  218  366\n",
       "207  2011-01-01      5   3034  2286  298  450\n",
       "246  2011-01-01      7   3040  2325  292  423\n",
       "263  2011-01-01      7   3055  2190  354  511\n",
       "300  2011-01-01      8   3150  2148  671  331\n",
       "312  2011-01-01      9   3036  2361  271  404\n",
       "313  2011-01-01      9   3005  2281  280  444\n",
       "430  2012-01-01      1   3253  2646  241  366\n",
       "493  2012-01-01      3   3034  2417  219  398\n",
       "498  2012-01-01      3   3065  2321  303  441\n",
       "502  2012-01-01      3   3044  2337  263  444\n",
       "507  2012-01-01      3   3137  2477  238  422\n",
       "508  2012-01-01      3   3019  2392  226  401\n",
       "519  2012-01-01      4   3019  2381  252  386\n",
       "520  2012-01-01      4   3002  2385  215  402\n",
       "526  2012-01-01      4   3209  2565  239  405\n",
       "527  2012-01-01      4   3154  2589  224  341\n",
       "529  2012-01-01      4   3144  2485  238  421\n",
       "532  2012-01-01      4   3347  2356  316  675\n",
       "533  2012-01-01      4   3046  2401  253  392\n",
       "536  2012-01-01      4   3060  2407  272  381\n",
       "543  2012-01-01      4   3040  2398  248  394\n",
       "550  2012-01-01      5   3018  2374  253  391\n",
       "557  2012-01-01      5   3050  2502  197  351\n",
       "558  2012-01-01      5   3116  2448  236  432\n",
       "562  2012-01-01      5   3050  2447  228  375\n",
       "563  2012-01-01      5   3080  2457  238  385\n",
       "564  2012-01-01      5   3137  2534  211  392\n",
       "569  2012-01-01      5   3041  2470  214  357\n",
       "570  2012-01-01      5   3091  2475  232  384\n",
       "...         ...    ...    ...   ...  ...  ...\n",
       "1071 2013-01-01     10   3083  2329  298  456\n",
       "1072 2013-01-01     10   3307  2595  257  455\n",
       "1075 2013-01-01     10   3044  2424  215  405\n",
       "1082 2013-01-01     10   3101  2465  217  419\n",
       "1089 2013-01-01     10   3040  2420  222  398\n",
       "1096 2013-01-01     11   3271  2530  281  460\n",
       "1110 2013-01-01     11   3042  2335  250  457\n",
       "1129 2013-01-01     12   3040  2350  250  440\n",
       "1130 2013-01-01     12   3111  2427  261  423\n",
       "1131 2013-01-01     12   3151  2449  246  456\n",
       "1144 2013-01-01     12   3051  2435  221  395\n",
       "1145 2013-01-01     12   3106  2373  299  434\n",
       "1187 2014-01-01      1   3066  2412  233  421\n",
       "1191 2014-01-01      2   3049  2382  241  426\n",
       "1208 2014-01-01      2   3013  2315  264  434\n",
       "1209 2014-01-01      2   3004  2302  233  469\n",
       "1220 2014-01-01      3   3012  2345  268  399\n",
       "1221 2014-01-01      3   3021  2402  216  403\n",
       "1229 2014-01-01      3   3053  2459  194  400\n",
       "1236 2014-01-01      3   3001  2374  216  411\n",
       "1247 2014-01-01      4   3018  2420  189  409\n",
       "1250 2014-01-01      4   3086  2421  231  434\n",
       "1254 2014-01-01      4   3063  2351  262  450\n",
       "1255 2014-01-01      4   3007  2388  206  413\n",
       "1256 2014-01-01      4   3024  2363  230  431\n",
       "1257 2014-01-01      4   3150  2448  252  450\n",
       "1258 2014-01-01      4   3101  2424  243  434\n",
       "1260 2014-01-01      4   3244  2541  269  434\n",
       "1261 2014-01-01      4   3099  2456  233  410\n",
       "1263 2014-01-01      4   3051  2383  245  423\n",
       "\n",
       "[273 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can explore rows with a specific value like so\n",
    "raw_data_df[raw_data_df[\"Total\"]>3000] # remove .head() to see all entires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entire table: 1268 \n",
      "Size of entires matching filter: 273 \n"
     ]
    }
   ],
   "source": [
    "# You can count the number of rows like so\n",
    "print(\"Size of entire table: %s \"%len(raw_data_df))\n",
    "print(\"Size of entires matching filter: %s \"%len(raw_data_df[raw_data_df[\"Total\"]>3000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can invert a match by using the 'not equal' evaluation.\n",
    "print(\"Size of entires matching filter: %s \"%len(raw_data_df[raw_data_df[\"What.is.your.annual.household.income.\"]!='R']))\n",
    "raw_data_df[raw_data_df[\"What.is.your.annual.household.income.\"]!='R'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can make a new table from your filtered rows like so\n",
    "processed_data_df = raw_data_df[raw_data_df[\"What.is.your.annual.household.income.\"]!='R']\n",
    "processed_data_df = processed_data_df[processed_data_df[\"Age.\"]!='R']\n",
    "# Note how I filtered first on raw_data_df and then on processed_data_df\n",
    "\n",
    "# Now let's remove all students\n",
    "processed_data_df = processed_data_df[processed_data_df[\"Are.you.a.student.\"]!='Yes']\n",
    "\n",
    "# So how many entires are there?\n",
    "print(\"Size of entire table: %s \"%len(processed_data_df))\n",
    "# Let's peak at the table.\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for the special case of when a calue is NaN, you can filter based on the value not being null (i.e., empty)\n",
    "processed_data_df = processed_data_df[pd.notnull(processed_data_df[\"What.is.your.annual.household.income.\"])]\n",
    "processed_data_df = processed_data_df[pd.notnull(processed_data_df[\"Age.\"])]\n",
    "print(\"Size of entire table: %s \"%len(processed_data_df)) # in the example data, this gets rid of a few rows\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can remove unwanted colums like so\n",
    "# for a single column\n",
    "processed_data_df = processed_data_df.drop('In.general..how.similar.are.you.to.other.people.you.know._2011', 1)\n",
    "# for multiple columns\n",
    "processed_data_df = processed_data_df.drop([\n",
    "                                            'How.satisfied.are.you.with.Somerville.as.a.place.to.live.',\n",
    "                                            'How.satisfied.are.you.with.your.neighborhood.'\n",
    "                                           ], 1)\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alternativly, if you want to make a new table from a subset of columns, you can do so like this.\n",
    "processed_data_df = processed_data_df[[\n",
    "                                        'How.happy.do.you.feel.right.now.', \n",
    "                                        'How.satisfied.are.you.with.your.life.in.general.', \n",
    "                                        'What.is.your.annual.household.income.',\n",
    "                                        'Age.'\n",
    "                                     ]].copy()\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can rename columns like so.\n",
    "processed_data_df = processed_data_df.rename(columns={\n",
    "                                                        'How.happy.do.you.feel.right.now.': 'happy', \n",
    "                                                        'How.satisfied.are.you.with.your.life.in.general.': 'satisfied',\n",
    "                                                        'What.is.your.annual.household.income.': 'income',\n",
    "                                                        'Age.': 'age',\n",
    "                                                     })\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can replace values in a column based on logic like so\n",
    "# Note: I used the unique values found above to inform my logic.\n",
    "# That is, I took the unique text lables and translated them into numbers.\n",
    "# It's clear that different surveys had different buckets. So I probably \n",
    "# sould limit myself to years using the same metrics, but for our purposes\n",
    "# I'm just going to run with a quick and dirty translation. \n",
    "\n",
    "processed_data_df.loc[processed_data_df['income'] == 'Less than $10,000', 'income'] = 5000 \n",
    "processed_data_df.loc[processed_data_df['income'] == '10,000 - $19,999', 'income'] = 15000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$10,000 to $24,999', 'income'] = 17500\n",
    "processed_data_df.loc[processed_data_df['income'] == '20,000 - $29,999', 'income'] = 25000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$25,000 to $49,999', 'income'] = 37500\n",
    "processed_data_df.loc[processed_data_df['income'] == '30,000 - $39,999', 'income'] = 35000\n",
    "processed_data_df.loc[processed_data_df['income'] == '40,000 - $49,999', 'income'] = 45000\n",
    "processed_data_df.loc[processed_data_df['income'] == '50,000 - $59,999', 'income'] = 55000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$50,000 to $74,999', 'income'] = 62500\n",
    "processed_data_df.loc[processed_data_df['income'] == '60,000 - $69,999', 'income'] = 65000\n",
    "processed_data_df.loc[processed_data_df['income'] == '70,000 - $79,999', 'income'] = 75000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$75,000 to $99,999', 'income'] = 87500\n",
    "processed_data_df.loc[processed_data_df['income'] == '80,000 - $89,999', 'income'] = 85000\n",
    "processed_data_df.loc[processed_data_df['income'] == '90,000 - $99,999', 'income'] = 95000\n",
    "processed_data_df.loc[processed_data_df['income'] == '100,000 and up', 'income'] = 100000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$100,000 to $149,999', 'income'] = 125000 \n",
    "processed_data_df.loc[processed_data_df['income'] == '$150,000 or more', 'income'] = 150000\n",
    "\n",
    "processed_data_df.loc[processed_data_df['age'] == '18-21', 'age'] = 24\n",
    "processed_data_df.loc[processed_data_df['age'] == '18-24', 'age'] = 21\n",
    "processed_data_df.loc[processed_data_df['age'] == '22-25', 'age'] = 23.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '25-34', 'age'] = 29.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '26-30', 'age'] = 28\n",
    "processed_data_df.loc[processed_data_df['age'] == '31-40', 'age'] = 35.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '35-44', 'age'] = 39.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '41-50', 'age'] = 46.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '45-54', 'age'] = 48\n",
    "processed_data_df.loc[processed_data_df['age'] == '51-60', 'age'] = 55.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '55-64', 'age'] = 58\n",
    "processed_data_df.loc[processed_data_df['age'] == '61+', 'age'] = 61\n",
    "processed_data_df.loc[processed_data_df['age'] == '65-74', 'age'] = 69.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '75 or older', 'age'] = 75\n",
    "processed_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To make sure all of your columns are stored as numbers, use the pd.to_numeric method like so.\n",
    "processed_data_df = processed_data_df.apply(pd.to_numeric, errors='coerce')\n",
    "# errors='coerce' will set things that can't be converted to numbers to NaN\n",
    "# so you'll want to drop these like so.\n",
    "processed_data_df = processed_data_df.dropna()\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can add a columns like so.\n",
    "processed_data_df[\"happy_Y_N\"] = \"N\"\n",
    "processed_data_df[\"satisfied_Y_N\"] = \"N\"\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And then you can customize these new coulmns using the same method as above. \n",
    "processed_data_df.loc[processed_data_df['happy'] >= 5, 'happy_Y_N'] = \"Y\"\n",
    "processed_data_df.loc[processed_data_df['satisfied'] >= 5, 'satisfied_Y_N'] = \"Y\"\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm now going to make a set of tables to be used in training some models\n",
    "# The first set will be for linear regressions where the traget is numeric.\n",
    "# Happiness\n",
    "happy_lin_df = processed_data_df[[\n",
    "                               'happy', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "happy_lin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Satisfaction\n",
    "sat_lin_df = processed_data_df[[\n",
    "                               'satisfied', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "sat_lin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The second set will be for classifiers where the target is a class.\n",
    "# Happiness\n",
    "happy_class_df = processed_data_df[[\n",
    "                               'happy_Y_N', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "happy_class_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Satisfaction\n",
    "sat_class_df = processed_data_df[[\n",
    "                               'satisfied_Y_N', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "sat_class_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taining and Validation\n",
    "\n",
    "Above I created four datasets worth exploring: \n",
    "- **`happy_lin_df`**. The data needed to access *happiness* along a continuous variable.\n",
    "- **`sat_lin_df`**. The data needed to access *satisfaction* along a continuous variable.\n",
    "- **`happy_class_df`**. The data needed to access *happiness* as a categorical variable.\n",
    "- **`sat_class_df`**. The data needed to access *satisfaction* as a categorical variable.\n",
    "\n",
    "Let's take them each in turn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy_lin_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = happy_lin_df\n",
    "\n",
    "data = data[data[\"happy\"]<=10]\n",
    "\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"happy\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"income\", y=\"happy\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ols(\"happy ~ age + income\", training).fit()\n",
    "#model = ols(\"happy ~ age + income + np.power(age, 2) + np.power(income, 2)\", training).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rerun with SciKitLearn because it's easy to check accuracy\n",
    "features_train = training.drop(\"happy\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"happy\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"happy\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"happy\"].as_matrix(columns=None)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "clf = lm.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = metrics.r2_score(labels_test, pred)\n",
    "print(\"R squared:\",lm.score(features_train,labels_train))\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sat_lin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sat_lin_df\n",
    "\n",
    "data = data[data[\"satisfied\"]<=10]\n",
    "\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"satisfied\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"income\", y=\"satisfied\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ols(\"satisfied ~ age + income\", training).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rerun with SciKitLearn because it's easy to check accuracy\n",
    "\n",
    "features_train = training.drop(\"satisfied\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"satisfied\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"satisfied\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"satisfied\"].as_matrix(columns=None)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "clf = lm.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = metrics.r2_score(labels_test, pred)\n",
    "print(\"R squared:\",lm.score(features_train,labels_train))\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = happy_class_df\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]\n",
    "\n",
    "# Define the target (y) and feature(s) (X)\n",
    "features_train = training.drop(\"happy_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"happy_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"happy_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"happy_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "# What percentage of the time is target Y?\n",
    "print(\"Percentage of Ys: %s\\n\"%(len(data[data[\"happy_Y_N\"]==\"Y\"])/len(data)))\n",
    "\n",
    "#### initial visualization\n",
    "feature_1_no = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_2_no = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_1_yes = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "feature_2_yes = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "plt.scatter(feature_1_yes, feature_2_yes, color = \"g\", label=\"Happy\")\n",
    "plt.scatter(feature_1_no, feature_2_no, color = \"r\", label=\"Unhappy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"income\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept = False, C = 1e9)\n",
    "clf = model.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Logistic Regression\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "# Test some spot\n",
    "x_test = 70\n",
    "y_test = 160000\n",
    "print(\"\")\n",
    "print(clf.predict([[x_test,y_test]])[0])\n",
    "print(clf.predict_proba([[x_test,y_test]])[0][1])\n",
    "print(\"\")\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"\\nDecision Tree\")\n",
    "evaluate(pred, labels_test)\n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Random Forest\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"rbf\",probability=True)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"SVM\")\n",
    "evaluate(pred, labels_test)  \n",
    "#plot_bound(\"Y\",holdout,1,2,0) # plot doesn't work with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sat_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sat_class_df\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]\n",
    "\n",
    "# Define the target (y) and feature(s) (X)\n",
    "features_train = training.drop(\"satisfied_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"satisfied_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"satisfied_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"satisfied_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "# What percentage of the time is target Y?\n",
    "print(\"Percentage of Ys: %s\\n\"%(len(data[data[\"satisfied_Y_N\"]==\"Y\"])/len(data)))\n",
    "\n",
    "#### initial visualization\n",
    "feature_1_no = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_2_no = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_1_yes = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "feature_2_yes = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "plt.scatter(feature_1_yes, feature_2_yes, color = \"g\", label=\"Happy\")\n",
    "plt.scatter(feature_1_no, feature_2_no, color = \"r\", label=\"Unhappy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"income\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept = False, C = 1e9)\n",
    "clf = model.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Logistic Regression\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "# Test some spot\n",
    "x_test = 70\n",
    "y_test = 160000\n",
    "print(\"\")\n",
    "print(clf.predict([[x_test,y_test]])[0])\n",
    "print(clf.predict_proba([[x_test,y_test]])[0][1])\n",
    "print(\"\")\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"\\nDecision Tree\")\n",
    "evaluate(pred, labels_test)\n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Random Forest\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"rbf\",probability=True)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"SVM\")\n",
    "evaluate(pred, labels_test)  \n",
    "#plot_bound(\"Y\",holdout,1,2,0) # plot doesn't work with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
