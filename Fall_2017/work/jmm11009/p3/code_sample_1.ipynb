{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Three Notebook\n",
    "\n",
    "By: Justin Martino [jmartino@su.suffolk.edu]\n",
    "\n",
    "\n",
    "\n",
    "## Load Some Stuff\n",
    "\n",
    "This is where we load libraires and the like so we can do what we need. If you get an error saying a module is not loaded, open a new terminal/cmd line and try running: `pip install [module name]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    inputFunc = raw_input\n",
    "except NameError:\n",
    "    inputFunc = input\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "import numpy as np\n",
    " \n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from patsy import dmatrices\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Custom functions\n",
    "\n",
    "def evaluate(pred, labels_test):\n",
    "    acc = accuracy_score(pred, labels_test)\n",
    "    print (\"Accuracey: %s\"%acc)\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test, pred).ravel()\n",
    "\n",
    "    recall = tp / (tp + fp)\n",
    "    percision = tp / (tp + fn)\n",
    "    f1 = (2 / ((1/recall)+(1/percision)))\n",
    "\n",
    "    print (\"\")\n",
    "    print (\"True Negatives: %s\"%tn)\n",
    "    print (\"False Positives: %s\"%fp)\n",
    "    print (\"False Negatives: %s\"%fn)\n",
    "    print (\"True Positives: %s\"%tp)\n",
    "    print (\"Recall: %s\"%recall)\n",
    "    print (\"Precision: %s\"%percision)\n",
    "    print (\"F1 Score: %s\"%f1)\n",
    "\n",
    "def plot_bound(Z_val,data,col1,col2,binary):\n",
    "    # Z-val equals \"Yes\" value. E.g., \"Y\" or \"1\". \n",
    "    # data equals df\n",
    "    # col1 and col2 defines which colums to use from data\n",
    "    # Plot binary decision boundary. \n",
    "    # For this, we will assign a color to each\n",
    "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "    \n",
    "    x_min = float(data.iloc[:,[col1]].min())-float(data.iloc[:,[col1]].min())*0.10 \n",
    "    x_max = float(data.iloc[:,[col1]].max()+float(data.iloc[:,[col1]].min())*0.10)\n",
    "    y_min = 0.0; \n",
    "    y_max = float(training.iloc[:,[col2]].max())+float(training.iloc[:,[col2]].max())*0.10\n",
    "    h_x = (x_max-x_min)/100  # step size in the mesh\n",
    "    h_y = (y_max-y_min)/100  # step size in the mesh\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h_x), np.arange(y_min, y_max, h_y))\n",
    "    if binary == 1:\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])   \n",
    "        Z = np.where(Z==\"Y\",1,0)\n",
    "    else:\n",
    "        Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.pcolormesh(xx, yy, Z)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Here we load the data we collected and get it all ready to feed to our statistical model(s). That is, we are trying to make a table with one **target** column and one or more **features**. Here I'm loading CareerWAR.csv from: http://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=y&type=8&season=2017&month=0&season1=1871&ind=0&team=0&rost=0&players=0 Note: you can find information on the data elements at this link. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>G</th>\n",
       "      <th>PA</th>\n",
       "      <th>HR</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babe Ruth</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2503</td>\n",
       "      <td>10616</td>\n",
       "      <td>714</td>\n",
       "      <td>2174</td>\n",
       "      <td>2217</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.690</td>\n",
       "      <td>168.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barry Bonds</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2986</td>\n",
       "      <td>12606</td>\n",
       "      <td>762</td>\n",
       "      <td>2227</td>\n",
       "      <td>1996</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.607</td>\n",
       "      <td>164.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Willie Mays</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2992</td>\n",
       "      <td>12493</td>\n",
       "      <td>660</td>\n",
       "      <td>2062</td>\n",
       "      <td>1903</td>\n",
       "      <td>338.0</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.557</td>\n",
       "      <td>149.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ty Cobb</td>\n",
       "      <td>- - -</td>\n",
       "      <td>3035</td>\n",
       "      <td>13072</td>\n",
       "      <td>117</td>\n",
       "      <td>2246</td>\n",
       "      <td>1937</td>\n",
       "      <td>892.0</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.512</td>\n",
       "      <td>149.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honus Wagner</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2792</td>\n",
       "      <td>11739</td>\n",
       "      <td>101</td>\n",
       "      <td>1736</td>\n",
       "      <td>1732</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.466</td>\n",
       "      <td>138.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name   Team     G     PA   HR     R   RBI     SB    AVG    OBP  \\\n",
       "0     Babe Ruth  - - -  2503  10616  714  2174  2217  123.0  0.342  0.474   \n",
       "1   Barry Bonds  - - -  2986  12606  762  2227  1996  514.0  0.298  0.444   \n",
       "2   Willie Mays  - - -  2992  12493  660  2062  1903  338.0  0.302  0.384   \n",
       "3       Ty Cobb  - - -  3035  13072  117  2246  1937  892.0  0.366  0.433   \n",
       "4  Honus Wagner  - - -  2792  11739  101  1736  1732  722.0  0.327  0.391   \n",
       "\n",
       "     SLG    WAR  \n",
       "0  0.690  168.4  \n",
       "1  0.607  164.4  \n",
       "2  0.557  149.9  \n",
       "3  0.512  149.3  \n",
       "4  0.466  138.1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and peek at your data. Change the file name as needed. \n",
    "raw_data_df = pd.read_csv('CareerWAR.csv', encoding = \"ISO-8859-1\") \n",
    "raw_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[714 762 660 117 101 755 521 301 475  47 493 696 536 511 548 297 586  83\n",
      " 534 268 512 452 431  97 614 399 118 138 317  73 468 462 361 240 449 160\n",
      " 106 184 630  84 389 105 113  67 563  45  96  92 504 260 342  40 316 569\n",
      " 324 307 224 183 612 311 383 359 376 244 234  28 435 434 198 170  75 251\n",
      " 555 583 573 291 390 309 385 135 314 393  68 258 248 185 358 427 210 407\n",
      " 132  53 130  34 252 509  54 201 351 126  86 414 331 282 253 426 609  27\n",
      "  70 465 438 162 288 379  29 255 137 332 154 294  56 242 366 202 377  48\n",
      "  57  33  31 354  65 122 287 369 205 236 182 257 223 128  62  63 215 284\n",
      " 102 169 165 382 186 278 541 119 340  26 178 199 440  74 261 231  32 374\n",
      " 306  12  13 247 140 275  20  71  49 292 238 256 348 319 189 195  41  46\n",
      " 173  22  42  35  21  69 409  79  18 207 200 378 352 235 141 246 203 398\n",
      " 151 473 127 339   7 239  38  64  94 219 100 149 110 300 181  80 136 370\n",
      " 190 164 208 155 335 353 229  90  58  23  91  59 381 281 157  43 263 188\n",
      " 222 220 237 196 305 304  81 302 193 412  98  61 112 194 277 360 241   9\n",
      "  55 384 386  66  10  78 206 350 272  95 293  17 104 139 174  44 175 163\n",
      " 271 172 204  85 299  60 134 197 192 213  52  87 226 320 336 267  39  88\n",
      "  93 147  51  36 108   8 321 166  89 152 176 266 228 124 264 167  15  25\n",
      " 156 328  37  72 103   6 249 115 146 323 168 120 338 150  16 179 148  77\n",
      " 191 217 211 245 133 109 143 131 318 325 171 279 116 153  11 227 355 315\n",
      " 270 233  99 123 221 107  82  19  14 129 439 111 259 142 262 159 310  24\n",
      " 214  50 187   2 125 442 265 218   4  30  76 286 180 121   3   1 114 396\n",
      " 161   5 230 144   0 145 274 158]\n",
      "[2217 1996 1903 ...,   46   43   30]\n"
     ]
    }
   ],
   "source": [
    "# You can explore unique entires by stating the column and using .unique() like this:\n",
    "print(raw_data_df[\"HR\"].unique())\n",
    "print(raw_data_df[\"RBI\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>G</th>\n",
       "      <th>PA</th>\n",
       "      <th>HR</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hank Aaron</td>\n",
       "      <td>- - -</td>\n",
       "      <td>3298</td>\n",
       "      <td>13940</td>\n",
       "      <td>755</td>\n",
       "      <td>2174</td>\n",
       "      <td>2297</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.555</td>\n",
       "      <td>136.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name   Team     G     PA   HR     R   RBI     SB    AVG    OBP  \\\n",
       "5  Hank Aaron  - - -  3298  13940  755  2174  2297  240.0  0.305  0.374   \n",
       "\n",
       "     SLG    WAR  \n",
       "5  0.555  136.3  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can explore rows with a specific value like so\n",
    "raw_data_df[raw_data_df[\"HR\"]== 755].head() # remove .head() to see all entires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entire table: 3962 \n",
      "Size of entires matching filter: 18 \n"
     ]
    }
   ],
   "source": [
    "# You can count the number of rows like so\n",
    "print(\"Size of entire table: %s \"%len(raw_data_df))\n",
    "print(\"Size of entires matching filter: %s \"%len(raw_data_df[raw_data_df[\"Team\"]=='Red Sox']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entires matching filter: 3944 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>G</th>\n",
       "      <th>PA</th>\n",
       "      <th>HR</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babe Ruth</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2503</td>\n",
       "      <td>10616</td>\n",
       "      <td>714</td>\n",
       "      <td>2174</td>\n",
       "      <td>2217</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.690</td>\n",
       "      <td>168.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barry Bonds</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2986</td>\n",
       "      <td>12606</td>\n",
       "      <td>762</td>\n",
       "      <td>2227</td>\n",
       "      <td>1996</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.607</td>\n",
       "      <td>164.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Willie Mays</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2992</td>\n",
       "      <td>12493</td>\n",
       "      <td>660</td>\n",
       "      <td>2062</td>\n",
       "      <td>1903</td>\n",
       "      <td>338.0</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.557</td>\n",
       "      <td>149.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ty Cobb</td>\n",
       "      <td>- - -</td>\n",
       "      <td>3035</td>\n",
       "      <td>13072</td>\n",
       "      <td>117</td>\n",
       "      <td>2246</td>\n",
       "      <td>1937</td>\n",
       "      <td>892.0</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.512</td>\n",
       "      <td>149.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honus Wagner</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2792</td>\n",
       "      <td>11739</td>\n",
       "      <td>101</td>\n",
       "      <td>1736</td>\n",
       "      <td>1732</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.466</td>\n",
       "      <td>138.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name   Team     G     PA   HR     R   RBI     SB    AVG    OBP  \\\n",
       "0     Babe Ruth  - - -  2503  10616  714  2174  2217  123.0  0.342  0.474   \n",
       "1   Barry Bonds  - - -  2986  12606  762  2227  1996  514.0  0.298  0.444   \n",
       "2   Willie Mays  - - -  2992  12493  660  2062  1903  338.0  0.302  0.384   \n",
       "3       Ty Cobb  - - -  3035  13072  117  2246  1937  892.0  0.366  0.433   \n",
       "4  Honus Wagner  - - -  2792  11739  101  1736  1732  722.0  0.327  0.391   \n",
       "\n",
       "     SLG    WAR  \n",
       "0  0.690  168.4  \n",
       "1  0.607  164.4  \n",
       "2  0.557  149.9  \n",
       "3  0.512  149.3  \n",
       "4  0.466  138.1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can invert a match by using the 'not equal' evaluation.\n",
    "print(\"Size of entires matching filter: %s \"%len(raw_data_df[raw_data_df[\"Team\"]!='Red Sox']))\n",
    "raw_data_df[raw_data_df[\"Team\"]!='Red Sox'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entire table: 3902 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>G</th>\n",
       "      <th>PA</th>\n",
       "      <th>HR</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babe Ruth</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2503</td>\n",
       "      <td>10616</td>\n",
       "      <td>714</td>\n",
       "      <td>2174</td>\n",
       "      <td>2217</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.690</td>\n",
       "      <td>168.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barry Bonds</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2986</td>\n",
       "      <td>12606</td>\n",
       "      <td>762</td>\n",
       "      <td>2227</td>\n",
       "      <td>1996</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.607</td>\n",
       "      <td>164.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Willie Mays</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2992</td>\n",
       "      <td>12493</td>\n",
       "      <td>660</td>\n",
       "      <td>2062</td>\n",
       "      <td>1903</td>\n",
       "      <td>338.0</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.557</td>\n",
       "      <td>149.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ty Cobb</td>\n",
       "      <td>- - -</td>\n",
       "      <td>3035</td>\n",
       "      <td>13072</td>\n",
       "      <td>117</td>\n",
       "      <td>2246</td>\n",
       "      <td>1937</td>\n",
       "      <td>892.0</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.512</td>\n",
       "      <td>149.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honus Wagner</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2792</td>\n",
       "      <td>11739</td>\n",
       "      <td>101</td>\n",
       "      <td>1736</td>\n",
       "      <td>1732</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.466</td>\n",
       "      <td>138.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name   Team     G     PA   HR     R   RBI     SB    AVG    OBP  \\\n",
       "0     Babe Ruth  - - -  2503  10616  714  2174  2217  123.0  0.342  0.474   \n",
       "1   Barry Bonds  - - -  2986  12606  762  2227  1996  514.0  0.298  0.444   \n",
       "2   Willie Mays  - - -  2992  12493  660  2062  1903  338.0  0.302  0.384   \n",
       "3       Ty Cobb  - - -  3035  13072  117  2246  1937  892.0  0.366  0.433   \n",
       "4  Honus Wagner  - - -  2792  11739  101  1736  1732  722.0  0.327  0.391   \n",
       "\n",
       "     SLG    WAR  \n",
       "0  0.690  168.4  \n",
       "1  0.607  164.4  \n",
       "2  0.557  149.9  \n",
       "3  0.512  149.3  \n",
       "4  0.466  138.1  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can make a new table from your filtered rows like so\n",
    "processed_data_df = raw_data_df[raw_data_df[\"AVG\"]!=.300]\n",
    "processed_data_df = processed_data_df[processed_data_df[\"Team\"]!='Red Sox']\n",
    "# Note how I filtered first on raw_data_df and then on processed_data_df\n",
    "\n",
    "# Now let's remove all students\n",
    "processed_data_df = processed_data_df[processed_data_df[\"Team\"]!='Yankees']\n",
    "\n",
    "# So how many entires are there?\n",
    "print(\"Size of entire table: %s \"%len(processed_data_df))\n",
    "# Let's peak at the table.\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of entire table: 3902 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>G</th>\n",
       "      <th>PA</th>\n",
       "      <th>HR</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>AVG</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babe Ruth</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2503</td>\n",
       "      <td>10616</td>\n",
       "      <td>714</td>\n",
       "      <td>2174</td>\n",
       "      <td>2217</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.690</td>\n",
       "      <td>168.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barry Bonds</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2986</td>\n",
       "      <td>12606</td>\n",
       "      <td>762</td>\n",
       "      <td>2227</td>\n",
       "      <td>1996</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.607</td>\n",
       "      <td>164.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Willie Mays</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2992</td>\n",
       "      <td>12493</td>\n",
       "      <td>660</td>\n",
       "      <td>2062</td>\n",
       "      <td>1903</td>\n",
       "      <td>338.0</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.557</td>\n",
       "      <td>149.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ty Cobb</td>\n",
       "      <td>- - -</td>\n",
       "      <td>3035</td>\n",
       "      <td>13072</td>\n",
       "      <td>117</td>\n",
       "      <td>2246</td>\n",
       "      <td>1937</td>\n",
       "      <td>892.0</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.512</td>\n",
       "      <td>149.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Honus Wagner</td>\n",
       "      <td>- - -</td>\n",
       "      <td>2792</td>\n",
       "      <td>11739</td>\n",
       "      <td>101</td>\n",
       "      <td>1736</td>\n",
       "      <td>1732</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.466</td>\n",
       "      <td>138.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name   Team     G     PA   HR     R   RBI     SB    AVG    OBP  \\\n",
       "0     Babe Ruth  - - -  2503  10616  714  2174  2217  123.0  0.342  0.474   \n",
       "1   Barry Bonds  - - -  2986  12606  762  2227  1996  514.0  0.298  0.444   \n",
       "2   Willie Mays  - - -  2992  12493  660  2062  1903  338.0  0.302  0.384   \n",
       "3       Ty Cobb  - - -  3035  13072  117  2246  1937  892.0  0.366  0.433   \n",
       "4  Honus Wagner  - - -  2792  11739  101  1736  1732  722.0  0.327  0.391   \n",
       "\n",
       "     SLG    WAR  \n",
       "0  0.690  168.4  \n",
       "1  0.607  164.4  \n",
       "2  0.557  149.9  \n",
       "3  0.512  149.3  \n",
       "4  0.466  138.1  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the special case of when a calue is NaN, you can filter based on the value not being null (i.e., empty)\n",
    "processed_data_df = processed_data_df[pd.notnull(processed_data_df[\"WAR\"])]\n",
    "processed_data_df = processed_data_df[pd.notnull(processed_data_df[\"AVG\"])]\n",
    "print(\"Size of entire table: %s \"%len(processed_data_df)) # in the example data, this gets rid of a few rows\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['SLG'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-11d24e0fd137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# You can remove unwanted colums like so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# for a single column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprocessed_data_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SLG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# for multiple columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m processed_data_df = processed_data_df.drop([\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2048\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2050\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2051\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3574\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3575\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3576\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3577\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['SLG'] not contained in axis"
     ]
    }
   ],
   "source": [
    "# You can remove unwanted colums like so\n",
    "# for a single column\n",
    "processed_data_df = processed_data_df.drop('SLG', 1)\n",
    "# for multiple columns\n",
    "processed_data_df = processed_data_df.drop([\n",
    "                                            'PA',\n",
    "                                            'R'\n",
    "                                           ], 1)\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAR</th>\n",
       "      <th>RBI</th>\n",
       "      <th>HR</th>\n",
       "      <th>SB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168.4</td>\n",
       "      <td>2217</td>\n",
       "      <td>714</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164.4</td>\n",
       "      <td>1996</td>\n",
       "      <td>762</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149.9</td>\n",
       "      <td>1903</td>\n",
       "      <td>660</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149.3</td>\n",
       "      <td>1937</td>\n",
       "      <td>117</td>\n",
       "      <td>892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138.1</td>\n",
       "      <td>1732</td>\n",
       "      <td>101</td>\n",
       "      <td>722.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WAR   RBI   HR     SB\n",
       "0  168.4  2217  714  123.0\n",
       "1  164.4  1996  762  514.0\n",
       "2  149.9  1903  660  338.0\n",
       "3  149.3  1937  117  892.0\n",
       "4  138.1  1732  101  722.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternativly, if you want to make a new table from a subset of columns, you can do so like this.\n",
    "processed_data_df = processed_data_df[[\n",
    "                                        'WAR', \n",
    "                                        'RBI', \n",
    "                                        'HR',\n",
    "                                        'SB'\n",
    "                                     ]].copy()\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-94-2b02b6a860c8>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-94-2b02b6a860c8>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    'RBI: 'HR',\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# You can rename columns like so.\n",
    "processed_data_df = processed_data_df.rename(columns={\n",
    "                                                        'AVG', \n",
    "                                                        'RBI: 'HR',\n",
    "                                                        'SB: 'R',\n",
    "                                                        'WAR: 'Name',\n",
    "                                                     })\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can replace values in a column based on logic like so\n",
    "# Note: I used the unique values found above to inform my logic.\n",
    "# That is, I took the unique text lables and translated them into numbers.\n",
    "# It's clear that different surveys had different buckets. So I probably \n",
    "# sould limit myself to years using the same metrics, but for our purposes\n",
    "# I'm just going to run with a quick and dirty translation. \n",
    "\n",
    "processed_data_df.loc[processed_data_df['income'] == 'Less than $10,000', 'income'] = 5000 \n",
    "processed_data_df.loc[processed_data_df['income'] == '10,000 - $19,999', 'income'] = 15000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$10,000 to $24,999', 'income'] = 17500\n",
    "processed_data_df.loc[processed_data_df['income'] == '20,000 - $29,999', 'income'] = 25000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$25,000 to $49,999', 'income'] = 37500\n",
    "processed_data_df.loc[processed_data_df['income'] == '30,000 - $39,999', 'income'] = 35000\n",
    "processed_data_df.loc[processed_data_df['income'] == '40,000 - $49,999', 'income'] = 45000\n",
    "processed_data_df.loc[processed_data_df['income'] == '50,000 - $59,999', 'income'] = 55000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$50,000 to $74,999', 'income'] = 62500\n",
    "processed_data_df.loc[processed_data_df['income'] == '60,000 - $69,999', 'income'] = 65000\n",
    "processed_data_df.loc[processed_data_df['income'] == '70,000 - $79,999', 'income'] = 75000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$75,000 to $99,999', 'income'] = 87500\n",
    "processed_data_df.loc[processed_data_df['income'] == '80,000 - $89,999', 'income'] = 85000\n",
    "processed_data_df.loc[processed_data_df['income'] == '90,000 - $99,999', 'income'] = 95000\n",
    "processed_data_df.loc[processed_data_df['income'] == '100,000 and up', 'income'] = 100000\n",
    "processed_data_df.loc[processed_data_df['income'] == '$100,000 to $149,999', 'income'] = 125000 \n",
    "processed_data_df.loc[processed_data_df['income'] == '$150,000 or more', 'income'] = 150000\n",
    "\n",
    "processed_data_df.loc[processed_data_df['age'] == '18-21', 'age'] = 24\n",
    "processed_data_df.loc[processed_data_df['age'] == '18-24', 'age'] = 21\n",
    "processed_data_df.loc[processed_data_df['age'] == '22-25', 'age'] = 23.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '25-34', 'age'] = 29.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '26-30', 'age'] = 28\n",
    "processed_data_df.loc[processed_data_df['age'] == '31-40', 'age'] = 35.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '35-44', 'age'] = 39.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '41-50', 'age'] = 46.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '45-54', 'age'] = 48\n",
    "processed_data_df.loc[processed_data_df['age'] == '51-60', 'age'] = 55.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '55-64', 'age'] = 58\n",
    "processed_data_df.loc[processed_data_df['age'] == '61+', 'age'] = 61\n",
    "processed_data_df.loc[processed_data_df['age'] == '65-74', 'age'] = 69.5\n",
    "processed_data_df.loc[processed_data_df['age'] == '75 or older', 'age'] = 75\n",
    "processed_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAR</th>\n",
       "      <th>RBI</th>\n",
       "      <th>HR</th>\n",
       "      <th>SB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168.4</td>\n",
       "      <td>2217</td>\n",
       "      <td>714</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>164.4</td>\n",
       "      <td>1996</td>\n",
       "      <td>762</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149.9</td>\n",
       "      <td>1903</td>\n",
       "      <td>660</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>149.3</td>\n",
       "      <td>1937</td>\n",
       "      <td>117</td>\n",
       "      <td>892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>138.1</td>\n",
       "      <td>1732</td>\n",
       "      <td>101</td>\n",
       "      <td>722.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WAR   RBI   HR     SB\n",
       "0  168.4  2217  714  123.0\n",
       "1  164.4  1996  762  514.0\n",
       "2  149.9  1903  660  338.0\n",
       "3  149.3  1937  117  892.0\n",
       "4  138.1  1732  101  722.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To make sure all of your columns are stored as numbers, use the pd.to_numeric method like so.\n",
    "processed_data_df = processed_data_df.apply(pd.to_numeric, errors='coerce')\n",
    "# errors='coerce' will set things that can't be converted to numbers to NaN\n",
    "# so you'll want to drop these like so.\n",
    "processed_data_df = processed_data_df.dropna()\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WAR</th>\n",
       "      <th>RBI</th>\n",
       "      <th>HR</th>\n",
       "      <th>SB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>2217</td>\n",
       "      <td>N</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>1996</td>\n",
       "      <td>N</td>\n",
       "      <td>514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>1903</td>\n",
       "      <td>N</td>\n",
       "      <td>338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>1937</td>\n",
       "      <td>N</td>\n",
       "      <td>892.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>1732</td>\n",
       "      <td>N</td>\n",
       "      <td>722.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WAR   RBI HR     SB\n",
       "0   N  2217  N  123.0\n",
       "1   N  1996  N  514.0\n",
       "2   N  1903  N  338.0\n",
       "3   N  1937  N  892.0\n",
       "4   N  1732  N  722.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can add a columns like so.\n",
    "processed_data_df[\"HR\"] = \"N\"\n",
    "processed_data_df[\"WAR\"] = \"N\"\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-4ae9f4cb012d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# And then you can customize these new coulmns using the same method as above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'WAR'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RBI'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'R'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'AVG'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprocessed_data_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.scalar_compare (pandas/_libs/lib.c:13713)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# And then you can customize these new coulmns using the same method as above. \n",
    "processed_data_df.loc[processed_data_df['HR'] <= 40, 'WAR'] = \"Y\"\n",
    "processed_data_df.loc[processed_data_df['RBI'] == 'R', 'AVG'] = \"Y\"\n",
    "processed_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['AVG'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-910a82d8f924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                \u001b[0;34m'HR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                \u001b[0;34m'RBI'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                \u001b[0;34m'AVG'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                                ]].copy()\n\u001b[1;32m      9\u001b[0m \u001b[0mhappy_lin_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2054\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2057\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2098\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['AVG'] not in index\""
     ]
    }
   ],
   "source": [
    "# I'm now going to make a set of tables to be used in training some models\n",
    "# The first set will be for linear regressions where the traget is numeric.\n",
    "# WAR\n",
    "happy_lin_df = processed_data_df[[\n",
    "                               'HR', \n",
    "                               'RBI', \n",
    "                               'AVG'\n",
    "                               ]].copy()\n",
    "happy_lin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Satisfaction\n",
    "sat_lin_df = processed_data_df[[\n",
    "                               'satisfied', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "sat_lin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The second set will be for classifiers where the target is a class.\n",
    "# Happiness\n",
    "happy_class_df = processed_data_df[[\n",
    "                               'happy_Y_N', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "happy_class_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Satisfaction\n",
    "sat_class_df = processed_data_df[[\n",
    "                               'satisfied_Y_N', \n",
    "                               'age', \n",
    "                               'income'\n",
    "                               ]].copy()\n",
    "sat_class_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taining and Validation\n",
    "\n",
    "Above I created four datasets worth exploring: \n",
    "- **`happy_lin_df`**. The data needed to access *happiness* along a continuous variable.\n",
    "- **`sat_lin_df`**. The data needed to access *satisfaction* along a continuous variable.\n",
    "- **`happy_class_df`**. The data needed to access *happiness* as a categorical variable.\n",
    "- **`sat_class_df`**. The data needed to access *satisfaction* as a categorical variable.\n",
    "\n",
    "Let's take them each in turn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy_lin_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-f0916f3d36ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inspection_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mholdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                              \"provide positive value.\")\n\u001b[1;32m   2899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0"
     ]
    }
   ],
   "source": [
    "data = happy_lin_df\n",
    "\n",
    "data = data[data[\"inspection_score\"]<=70]\n",
    "\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-c02e454039c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"WAR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training' is not defined"
     ]
    }
   ],
   "source": [
    "sns.lmplot(x=\"WAR\", y=\"HR\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-1759ef013a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"violation_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inspection_score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'training' is not defined"
     ]
    }
   ],
   "source": [
    "sns.lmplot(x=\"violation_id\", y=\"inspection_score\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-17ed1a816f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inspection_score ~ risk_category + violation_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#model = ols(\"happy ~ age + income + np.power(age, 2) + np.power(income, 2)\", training).fit()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training' is not defined"
     ]
    }
   ],
   "source": [
    "model = ols(\"inspection_score ~ risk_category + violation_id\", training).fit()\n",
    "#model = ols(\"happy ~ age + income + np.power(age, 2) + np.power(income, 2)\", training).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rerun with SciKitLearn because it's easy to check accuracy\n",
    "features_train = training.drop(\"happy\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"happy\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"happy\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"happy\"].as_matrix(columns=None)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "clf = lm.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = metrics.r2_score(labels_test, pred)\n",
    "print(\"R squared:\",lm.score(features_train,labels_train))\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sat_lin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sat_lin_df\n",
    "\n",
    "data = data[data[\"satisfied\"]<=10]\n",
    "\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"age\", y=\"satisfied\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"income\", y=\"satisfied\", data=training, x_estimator=np.mean, order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ols(\"satisfied ~ age + income\", training).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rerun with SciKitLearn because it's easy to check accuracy\n",
    "\n",
    "features_train = training.drop(\"satisfied\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"satisfied\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"satisfied\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"satisfied\"].as_matrix(columns=None)\n",
    "\n",
    "lm = linear_model.LinearRegression()\n",
    "clf = lm.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "accuracy = metrics.r2_score(labels_test, pred)\n",
    "print(\"R squared:\",lm.score(features_train,labels_train))\n",
    "print(\"Accuracy:\",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## happy_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = happy_class_df\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]\n",
    "\n",
    "# Define the target (y) and feature(s) (X)\n",
    "features_train = training.drop(\"happy_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"happy_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"happy_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"happy_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "# What percentage of the time is target Y?\n",
    "print(\"Percentage of Ys: %s\\n\"%(len(data[data[\"happy_Y_N\"]==\"Y\"])/len(data)))\n",
    "\n",
    "#### initial visualization\n",
    "feature_1_no = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_2_no = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_1_yes = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "feature_2_yes = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "plt.scatter(feature_1_yes, feature_2_yes, color = \"g\", label=\"Happy\")\n",
    "plt.scatter(feature_1_no, feature_2_no, color = \"r\", label=\"Unhappy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"income\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept = False, C = 1e9)\n",
    "clf = model.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Logistic Regression\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "# Test some spot\n",
    "x_test = 70\n",
    "y_test = 160000\n",
    "print(\"\")\n",
    "print(clf.predict([[x_test,y_test]])[0])\n",
    "print(clf.predict_proba([[x_test,y_test]])[0][1])\n",
    "print(\"\")\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"\\nDecision Tree\")\n",
    "evaluate(pred, labels_test)\n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Random Forest\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"rbf\",probability=True)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"SVM\")\n",
    "evaluate(pred, labels_test)  \n",
    "#plot_bound(\"Y\",holdout,1,2,0) # plot doesn't work with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sat_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sat_class_df\n",
    "holdout = data.sample(frac=0.05)\n",
    "training = data.loc[~data.index.isin(holdout.index)]\n",
    "\n",
    "# Define the target (y) and feature(s) (X)\n",
    "features_train = training.drop(\"satisfied_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_train = training[\"satisfied_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "features_test = holdout.drop(\"satisfied_Y_N\", axis=1).as_matrix(columns=None)\n",
    "labels_test = holdout[\"satisfied_Y_N\"].as_matrix(columns=None)\n",
    "\n",
    "# What percentage of the time is target Y?\n",
    "print(\"Percentage of Ys: %s\\n\"%(len(data[data[\"satisfied_Y_N\"]==\"Y\"])/len(data)))\n",
    "\n",
    "#### initial visualization\n",
    "feature_1_no = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_2_no = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"N\"]\n",
    "feature_1_yes = [features_test[ii][0] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "feature_2_yes = [features_test[ii][1] for ii in range(0, len(features_test)) if labels_test[ii]==\"Y\"]\n",
    "plt.scatter(feature_1_yes, feature_2_yes, color = \"g\", label=\"Happy\")\n",
    "plt.scatter(feature_1_no, feature_2_no, color = \"r\", label=\"Unhappy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"income\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model = LogisticRegression(fit_intercept = False, C = 1e9)\n",
    "clf = model.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Logistic Regression\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "# Test some spot\n",
    "x_test = 70\n",
    "y_test = 160000\n",
    "print(\"\")\n",
    "print(clf.predict([[x_test,y_test]])[0])\n",
    "print(clf.predict_proba([[x_test,y_test]])[0][1])\n",
    "print(\"\")\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"\\nDecision Tree\")\n",
    "evaluate(pred, labels_test)\n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"Random Forest\")\n",
    "evaluate(pred, labels_test)  \n",
    "plot_bound(\"Y\",holdout,1,2,0)\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel=\"rbf\",probability=True)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "print(\"SVM\")\n",
    "evaluate(pred, labels_test)  \n",
    "#plot_bound(\"Y\",holdout,1,2,0) # plot doesn't work with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
